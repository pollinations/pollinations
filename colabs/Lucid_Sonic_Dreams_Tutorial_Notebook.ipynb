{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lucid Sonic Dreams - Tutorial Notebook",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pollinations/pollinations/blob/master/colabs/Lucid_Sonic_Dreams_Tutorial_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSBBXrcy1ssE"
      },
      "source": [
        "# A. Set-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kBYttBTtlho"
      },
      "source": [
        "## A.1. Set-up GPU\n",
        "\n",
        "Navigate to **Runtime -> Change runtime type** and make sure **Hardware accelerator** is set to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1OB-5oZxV0y"
      },
      "source": [
        "## A.2. Download Sample Audio Preview Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldjd9LiHxZNG"
      },
      "source": [
        "## CHEMICAL LOVE - BASICALLY SATURDAY NIGHT ## \n",
        "\n",
        "! gdown --id 1aTWrzCvJyYcQ82PS6av3YJrtsON2_CUK\n",
        "\n",
        "## PANCAKE FEET - TENNYSSON ## \n",
        "\n",
        "! gdown --id 14MqCkuREr1TmuWaxZd8bnuhVlL_vCE9s\n",
        "\n",
        "## RASPBERRY - SAJE ## \n",
        "\n",
        "! gdown --id 1GqRi4VFEbw46e9RRvuGPtNc7TuOKFbjl\n",
        "\n",
        "## LUCID SONIC DREAMS DEMO TRACK ##\n",
        "\n",
        "# Main File\n",
        "! gdown --id 1Vc2yC2F5iO0ScC5F0CzF_YB1YPGI2uUP\n",
        "\n",
        "# Pulse File \n",
        "! gdown --id 1FY5MO6XqVu9abbdNQQY6C99RHxFGm36o\n",
        "\n",
        "# Class File\n",
        "! gdown --id 1-qwcs8_Va58YqkHMdXDm9uef-RcH01gh\n",
        "\n",
        "## SEA OF VOICES - PORTER ROBINSON ##\n",
        "\n",
        "# Instrumental (Main Audio)\n",
        "! gdown --id 13-kS5-3Tw2x9kEVfE3ZMkUN955nw73mN\n",
        "\n",
        "# Original (Output Audio)\n",
        "! gdown --id 1r0Mo-vtUIf2njqJ0h3hPJuQELcJ8K2Gu\n",
        "\n",
        "## UNFAITH - EKALI ## \n",
        "! gdown --id 1rgwrhtnVwK2Dom9pJ7p2CBF0j7F2vdkM\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PByrKtjcuMP8"
      },
      "source": [
        "## A.3. Install Lucid Sonic Dreams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50buTzTKOf6x",
        "outputId": "b4384509-769a-4e58-dbad-ece9d1c3185f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install lucidsonicdreams"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lucidsonicdreams\n",
            "  Downloading lucidsonicdreams-0.4.tar.gz (11 kB)\n",
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 21 kB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.19.5)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.2.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (4.62.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.4.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.16.2)\n",
            "Collecting pygit2\n",
            "  Downloading pygit2-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 26.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (3.6.4)\n",
            "Collecting mega.py\n",
            "  Downloading mega.py-1.0.8-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (1.1.5)\n",
            "Requirement already satisfied: SoundFile in /usr/local/lib/python3.7/dist-packages (from lucidsonicdreams) (0.10.3.post1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.12.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 21.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.39.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->lucidsonicdreams) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15->lucidsonicdreams) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (4.6.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15->lucidsonicdreams) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->lucidsonicdreams) (3.7.4.3)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (0.51.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (0.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (21.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (1.0.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (0.22.2.post1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->lucidsonicdreams) (1.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->lucidsonicdreams) (0.34.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->lucidsonicdreams) (2.4.7)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->lucidsonicdreams) (1.4.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile->lucidsonicdreams) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->SoundFile->lucidsonicdreams) (2.20)\n",
            "Collecting pycryptodome<4.0.0,>=3.9.6\n",
            "  Downloading pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from mega.py->lucidsonicdreams) (1.0.1)\n",
            "Collecting tenacity<6.0.0,>=5.1.5\n",
            "  Downloading tenacity-5.1.5-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lucidsonicdreams) (2021.5.30)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->lucidsonicdreams) (2.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->lucidsonicdreams) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->lucidsonicdreams) (2.8.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (2.6.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lucidsonicdreams) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->lucidsonicdreams) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->lucidsonicdreams) (1.3.1)\n",
            "Building wheels for collected packages: lucidsonicdreams, gast\n",
            "  Building wheel for lucidsonicdreams (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lucidsonicdreams: filename=lucidsonicdreams-0.4-py3-none-any.whl size=11498 sha256=9ea6f534eba80df45957f858241e34b2a7a78cd6b228425055feaeb43cf5e664\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/23/3e/f6f4265bde5ac9993ce077083c570dd06032867ae0aadd3481\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=9f42113abdaa0e522de8ef01e15c2e4cd64b71869bcd2f4c654c140508529496\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built lucidsonicdreams gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tenacity, pycryptodome, keras-applications, gast, tensorflow, pygit2, mega.py, lucidsonicdreams\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 lucidsonicdreams-0.4 mega.py-1.0.8 pycryptodome-3.10.1 pygit2-1.6.1 tenacity-5.1.5 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63dO9FBu1Mv0"
      },
      "source": [
        "# B. Generate Sample Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AgAsUB54ej8"
      },
      "source": [
        "## B.1. Choosing a Style\n",
        "\n",
        "Styles can be selected using the **style** parameter, which takes in any of the following:\n",
        "\n",
        "*   A valid default style name provided by the package. Run **show_styles()** to print valid values. *Note: These styles are loaded from [this repository](https://github.com/justinpinkney/awesome-pretrained-stylegan2) by Justin Pinkney.*\n",
        "\n",
        "*   A path to a .pkl file that contains pre-trained StyleGAN weights\n",
        "\n",
        "*   A custom function that takes noise_batch and class_batch parameters and outputs a list of Pillow Images (see example in **B.5**)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak17n4mm81Hm",
        "outputId": "2b8409bb-7120-4d57-a0f4-22ecae491f72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from lucidsonicdreams import show_styles \n",
        "\n",
        "# Show valid default style names. \n",
        "show_styles()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2367488/45929032 bytes (5.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5636096/45929032 bytes (12.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8847360/45929032 bytes (19.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11739136/45929032 bytes (25.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14704640/45929032 bytes (32.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18063360/45929032 bytes (39.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b21381120/45929032 bytes (46.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24264704/45929032 bytes (52.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27426816/45929032 bytes (59.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30752768/45929032 bytes (67.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33832960/45929032 bytes (73.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37093376/45929032 bytes (80.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40509440/45929032 bytes (88.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43679744/45929032 bytes (95.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n",
            "ffhq faces\n",
            "horse\n",
            "flowers\n",
            "anime faces\n",
            "ukiyo-e faces\n",
            "obama\n",
            "wikiart\n",
            "anime portraits\n",
            "panda\n",
            "car (config-f)\n",
            "grumpy cat\n",
            "faces (ffhq slim 256x256)\n",
            "painting faces\n",
            "more abstract art\n",
            "butterflies\n",
            "wikiart faces\n",
            "imagenet\n",
            "cifar 10\n",
            "faces (ffhq config-e)\n",
            "beetles\n",
            "wildlife\n",
            "church\n",
            "abstract photos\n",
            "abstract art\n",
            "ukiyoe faces\n",
            "fursona\n",
            "fireworks\n",
            "microscope images\n",
            "figure drawings\n",
            "maps\n",
            "car (config-e)\n",
            "lsun bedrooms\n",
            "lsun cats\n",
            "faces (ffhq config-e 256x256)\n",
            "my little pony\n",
            "floor plans\n",
            "trypophobia\n",
            "pokemon\n",
            "cakes\n",
            "cifar 100\n",
            "doors\n",
            "modern art\n",
            "cat\n",
            "vases\n",
            "faces (ffhq config-f)\n",
            "textures\n",
            "lsun cars\n",
            "faces (ffhq config-f 512x512)\n",
            "celeba hq faces\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNnHbJgB2EWk"
      },
      "source": [
        "## B.2. Using Default Settings\n",
        "\n",
        "This package is set-up so that the only arguments required are the **file path to your audio track** and the **file name of the video output**. This code snippet outputs a 45-second, low-resolution preview of a video using the \"modern art\" style, and all the other default settings.\n",
        "\n",
        "The song used here is **Chemical Love by Basically Saturday Night**. You can watch the official music video [here](https://youtu.be/Gi7oQrtyjKI), or listen to them on [Spotify](https://open.spotify.com/artist/46tGdhXAQbTvxVOGgy0Fqu?si=E8mUjbWbR2uiiMR2MUc_4w)!\n",
        "\n",
        "Click [here](https://youtu.be/oGXfOmqFYTg) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7DkKcO9cfM_",
        "outputId": "317e623e-94bf-4c4a-8f77-625bea9bcd52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from lucidsonicdreams import LucidSonicDream\n",
        "from google.colab import files\n",
        "\n",
        "styles=[\"abstract art\", \"trypophobia\", \"more abstract art\"]\n",
        "\n",
        "def render_in_style(style):\n",
        "  L = LucidSonicDream(song = 'suprassumo.mp3',\n",
        "                      style = style)\n",
        "\n",
        "  L.hallucinate(file_name = f'suprassumo_{style}.mp4',\n",
        "                resolution = 640,\n",
        "                #start = 30, \n",
        "                #duration = 45\n",
        "                )\n",
        "\n",
        "  files.download(f'suprassumo_{style}.mp4',)\n",
        "\n",
        "for style in styles:\n",
        "  render_in_style(style)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing style...\n",
            "Downloading abstract art weights (This may take a while)...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YzZemZAp7BVW701_BZ7uabJWJJaS2g7v\n",
            "To: /content/abstract art.pkl\n",
            "382MB [00:03, 113MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Download complete\n",
            "Preparing audio...\n",
            "Loading effects...\n",
            "\n",
            "\n",
            "Doing math...\n",
            "\n",
            "\n",
            "\n",
            "Hallucinating... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8422/8422 [35:50<00:00,  3.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] >>>> Building video suprassumo_abstract art.mp4\n",
            "[MoviePy] Writing audio in suprassumo_abstract artTEMP_MPY_wvf_snd.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4313/4313 [00:09<00:00, 438.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video suprassumo_abstract art.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 8423/8423 [06:11<00:00, 22.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: suprassumo_abstract art.mp4 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_89e2cca5-5204-4780-a893-a0cc841a0adc\", \"suprassumo_abstract art.mp4\", 26554433)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Preparing style...\n",
            "Downloading trypophobia weights (This may take a while)...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12yYXZymadSIj74Yue1Q7RrlbIqrXggo3\n",
            "To: /content/trypophobia.pkl\n",
            "382MB [00:04, 78.7MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Download complete\n",
            "Preparing audio...\n",
            "Loading effects...\n",
            "\n",
            "\n",
            "Doing math...\n",
            "\n",
            "\n",
            "\n",
            "Hallucinating... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8422/8422 [34:53<00:00,  4.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] >>>> Building video suprassumo_trypophobia.mp4\n",
            "[MoviePy] Writing audio in suprassumo_trypophobiaTEMP_MPY_wvf_snd.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4313/4313 [00:09<00:00, 450.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video suprassumo_trypophobia.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 8423/8423 [07:07<00:00, 19.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: suprassumo_trypophobia.mp4 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_eac98464-ad35-4bca-a5a2-eb6673d671d1\", \"suprassumo_trypophobia.mp4\", 77571642)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Preparing style...\n",
            "Downloading more abstract art weights (This may take a while)...\n",
            "Download complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Permission denied: https://drive.google.com/uc?id=1wSTYii46Q4dqp70iDCFApQOQIfl5q4EL\n",
            "Maybe you need to change permission over 'Anyone with the link'?\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-87d089cc9086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstyles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mrender_in_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-87d089cc9086>\u001b[0m in \u001b[0;36mrender_in_style\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   L.hallucinate(file_name = f'suprassumo_{style}.mp4',\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mresolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;31m#start = 30,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;31m#duration = 45\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lucidsonicdreams/main.py\u001b[0m in \u001b[0;36mhallucinate\u001b[0;34m(self, file_name, output_audio, fps, resolution, start, duration, save_frames, batch_size, speed_fpm, pulse_percussive, pulse_harmonic, pulse_react, motion_percussive, motion_harmonic, motion_react, motion_randomness, truncation, classes, dominant_classes_first, class_pitch_react, class_smooth_seconds, class_complexity, class_shuffle_seconds, class_shuffle_strength, contrast_strength, contrast_percussive, flash_strength, flash_percussive, custom_effects)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstylegan_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lucidsonicdreams/main.py\u001b[0m in \u001b[0;36mstylegan_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Load weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'more abstract art.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzP-pZQc2vVp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCo0pQkHANuA"
      },
      "source": [
        "## B.3. Tuning Parameters - How It Works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuLiMg9CUXvG"
      },
      "source": [
        "There are **over 30 parameters** you can tune, offering tons of flexibility as to how you want your music to be visualized. This may seem like an overwhelming number, but things are easier to digest once you have a basic understanding of how the visualizer works.\n",
        "\n",
        "### So, how does it work? \n",
        "\n",
        "1. First, a batch of input vectors corresponding to output images is initialized. Linear interpolations between these vectors are produced, serving as the \"base\" vectors.\n",
        "2. Three components react to the audio: **Pulse**, **Motion**, and **Class**. These modify the \"base\" vectors accordingly.\n",
        "\n",
        "  *   **Pulse**, quite literally, refers to how the visuals \"pulse\" to the beat of the music. It is set to react to the audio's percussive elements by default. \n",
        "  *   **Motion** refers to how the visuals are \"pushed forward\" or \"sped up\" by the music, and is set to react to the audio's harmonic elements by default. \n",
        "  *   Finally, **Class** refers to the labels of objects shown in the generated images (e.g. in the case of the WikiArt style, classes can refer to Van Gogh, Andy Warhol, Da Vinci, etc). This is set to react to the audio's pitch, where each note controls the prominence of a class. *Note:* Among the default styles available, only WikiArt uses classes thus far.\n",
        "3. Finally, additional effects - such as contrast and flash - are added to the video. These are set to react to the audio's percussive elements by default.\n",
        "\n",
        "### The Parameters\n",
        "\n",
        "Now, the parameters can be easily understood by separating them into 7 categories: Initialization, Pulse, Motion, Class, Effects, Video, and Other. \n",
        "\n",
        "If this is still overwhelming, it's recommended that you start off by tuning **speed_fpm**, **pulse_react**, **motion_react** and **class_pitch_react**, and build from there. These parameters make the biggest difference.\n",
        "\n",
        "##### **Initialization**\n",
        "\n",
        "* **speed_fpm** (*Default: 12*) - FPM stands for \"Frames per Minute\". This determines how many images are initialized - the more there are, the faster the visuals morph. If **speed_fpm = 0**, then only one image is initialized, and that single image reacts to the audio. In this case, there will be no motion during silent parts of the audio.\n",
        "\n",
        "##### **Pulse Parameters**\n",
        "\n",
        "*   **pulse_react** (*Default: 0.5*) - The \"strength\" of the pulse. It is recommended to keep this between 0 and 2.\n",
        "*   **pulse_percussive** (*Default: True*) - If True while *pulse_harmonic* is False, pulse reacts to the audio's percussive elements.\n",
        "*   **pulse_harmonic** (*Default: False*) - If True while *pulse_percussive* is False, pulse reacts to the audio's harmonic elements.\n",
        "\n",
        "  *Note*: If both parameters are True or both parameters are False, pulse reacts to the \"entire\" unaltered audio.\n",
        "*   **pulse_audio** - Path to a separate audio file to be used to control pulse. This is recommended if you have access to an isolated drum/percussion track. If passed, *pulse_percussive* and *pulse_harmonic* are ignored. *Note:* this parameter is passed when defining the LucidSonicDream object.\n",
        "\n",
        "##### **Motion Parameters**\n",
        "\n",
        "*   **motion_react** (*0.5*), **motion_percussive** (*False*), **motion_harmonic** (*True*), and **motion_audio** - Simply the \"motion\" equivalents of the pulse parameters above. \n",
        "*   **motion_randomness** (*Default: 0.5*)- Degree of randomness of motion. Higher values will typically prevent the video from cycling through the same visuals repeatedly. Must range from 0 to 1.\n",
        "*   **truncation** (*Default: 1*) - Controls the variety of visuals generated. Lower values lead to lower variety. *Note*: A very low value will usually lead to \"jittery\" visuals. Must range from 0 to 1.\n",
        "\n",
        "##### **Class Parameters** \n",
        "\n",
        "*(Note: Most of these parameters were heavily inspired by the [Deep Music Visualizer](https://github.com/msieg/deep-music-visualizer) project by Matt Siegelman)*\n",
        "\n",
        "*   **classes** - List of at most 12 numerical object labels. If none, 12 labels are selected at random. \n",
        "*   **dominant_classes_first** (*Default: False*)- If True, the list passed to \"classes\" is sorted by prominence in descending order.\n",
        "*   **class_pitch_react** (*Default: 0.5*)- Class equivalent of pulse_react and motion_react. It is recommended to keep this between 0 and 2.\n",
        "*   **class_smooth_seconds** (*Default: 1*) - Number of seconds spent smoothly interpolating between each class vector. The higher the value, the less \"sudden\" the change of class.\n",
        "*   **class_complexity** (*Default: 1*) - Controls the \"complexity\" of images generated. Lower values tend to generate more simple and mundane images, while higher values tend to generate more intricate and bizzare objects. It is recommended to keep this between 0 and 1.\n",
        "*   **class_shuffle_seconds** (*Default: None*) - Controls the timestamps wherein the mapping of label to note is re-shuffled. This is recommended when the audio used has a limited range of pitches, but you wish for more classes to be shown. If the value passed is a number *n*, classes are shuffled every *n* seconds. If the value passed is a list of numbers, these numbers are used as timestamps (in seconds) wherein classes are shuffled.\n",
        "*   **class_shuffle_strength** (*Default: 0.5*) - Controls how drastically classes are re-shuffled. Only applies when class_shuffle_seconds is passed. It is recommended to keep this between 0 and 1.\n",
        "*   **class_audio** - Class equivalent of pulse_audio and motion_audio. Passed when defining the LucidSonicDream object. \n",
        "\n",
        "##### **Effects Parameters**\n",
        "\n",
        "*   **contrast_strength** (*Default: 0.5*) - Strength of default contrast effect. It is recommended to keep this between 0 and 1.\n",
        "*   **contrast_percussive** (*Default: True*) - If true, contrast reacts to the audio's percussive elements. Must range from 0 to 1.\n",
        "*   **contrast_audio** - Equivalent of previous \"audio\" arguments. Passed when defining the LucidSonicDream object.  \n",
        "\n",
        "  *Note*: If none of these arguments are passed, the contrast effect will not be applied. \n",
        "\n",
        "*   **flash_strength** (*0.5*), **flash_percussive** (*True*), and **flash_audio** - Equivalent of the previous three parameters, but for the a \"flash\" effect. It is recommended to keep these between 0 and 1. If none of these arguments are passed, the flash effect will not be applied. \n",
        "*   **custom_effects** - List of custom, user-defined effects to apply (See **B.4**)\n",
        "\n",
        "##### **Video Parameters**\n",
        "\n",
        "*   **resolution** - Self-explanatory. Low resolutions are recommended for \"trial\" renders. If none is passed, unaltered high-resolution images will be used.\n",
        "*   **start** (*Default: 0*) - Starting timestamp in seconds.\n",
        "*   **duration** - Video duration in seconds. If none is passed, full duration of audio will be used.\n",
        "*   **output_audio** - Final output audio of the video. Overwrites audio from \"song\" parameter if provided (See **B.5**)\n",
        "*   **fps** (*Default: 43*) - Video Frames Per Second. \n",
        "*   **save_frames** (*Default: False*) - If true, saved all individual video frames on disk.\n",
        "\n",
        "##### **Other**\n",
        "\n",
        "*   **batch_size** (*Default: 1*) - Determines how many vectors are simoultaneously fed to the model. Typically, larger batch sizes will output less clearly-defined images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ARd-chd2dCm"
      },
      "source": [
        "#### Example 1 \n",
        "\n",
        "This is a simple example whose appeal lies mostly in how it utilizes Motion.\n",
        "\n",
        "The song used here is **Pancake Feet by Tennysson**. As usual, you can watch the official music video [here](https://youtu.be/_ODm4UZGh7g), or listen to them on [Spotify](https://open.spotify.com/artist/3Nb8N20WChM0swo5qWTvm8?si=oUZ2uV7eQH2ieMucvL_vgA)!\n",
        "\n",
        "Click [here](https://youtu.be/ztWCMm9cExY) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTd6MslThkxX"
      },
      "source": [
        "L = LucidSonicDream('pancake_feet.mp3',\n",
        "                    style = 'modern art')\n",
        "\n",
        "L.hallucinate('pancake_feet.mp4',\n",
        "              resolution = 360,\n",
        "              duration = 45,\n",
        "              speed_fpm = 0,\n",
        "              motion_percussive = True,\n",
        "              motion_react = 0.8,\n",
        "              contrast_strength = 0.5,\n",
        "              flash_strength = 0.7)\n",
        "\n",
        "files.download(\"pancake_feet.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAy9aNsg_JYq"
      },
      "source": [
        "#### Example 2\n",
        "\n",
        "This is another simple example that combines subtle Pulse, Motion, Contrast, and Flash reactions to complement the overall trippy style. \n",
        "\n",
        "The style weights used here are from a model trained by **Jeremy Torman**. You can check out his artworks on [Twitter](https://twitter.com/tormanjeremy), or see details on his [original Reddit post](https://www.reddit.com/r/deepdream/comments/leqwxs/stylegan2ada_pickle_file_in_comments_with_colab/) if you're interested!\n",
        "\n",
        "The song, meanwhile, is **Raspberry by Saje**. You can listen to the full track on [YouTube](https://www.youtube.com/watch?v=fOLxvL0_aMU) or [Spotify](https://open.spotify.com/artist/3I2596dGk4K3e4qKjwpzQb?si=TbyjmQuAQRWmrE--lNTRMg). \n",
        "\n",
        "Click [here](https://youtu.be/iEFqcMrszH0) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGvz9tH_CXrf"
      },
      "source": [
        "# Download Style Weights \n",
        "! gdown --id 19hNptJSXji_9h7DMJBVlEMe-izWXvkYQ\n",
        "\n",
        "L = LucidSonicDream(song = 'raspberry.mp3',\n",
        "                    style = 'VisionaryArt.pkl')\n",
        "\n",
        "L.hallucinate(file_name = 'raspberry.mp4',\n",
        "              resolution = 360,\n",
        "              duration = 60,\n",
        "              pulse_react = 1.2,\n",
        "              motion_react = 0.7,\n",
        "              contrast_strength = 0.5,\n",
        "              flash_strength = 0.5)\n",
        "\n",
        "files.download(\"raspberry.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EraHol-d3FLb"
      },
      "source": [
        "#### Example 3\n",
        "\n",
        "This is a much more complex example that utilizes multiple audio tracks and more fine-tuned parameters. It takes advantage of isolated audio tracks for cleaner Pulse, Class, and Contrast reactions.\n",
        "\n",
        "Note: Numerical labels for classes using the WikiArt style can be found [here](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_Example_Generation_By_Peter_Baylies.ipynb). \n",
        "\n",
        "Click [here](https://youtu.be/l-nGC-ve7sI) to view a full-length sample video without having to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZL5yNGYV8kN"
      },
      "source": [
        "L = LucidSonicDream(song = 'lucidsonicdreams_main.mp3',\n",
        "                    pulse_audio = 'lucidsonicdreams_pulse.mp3',\n",
        "                    class_audio = 'lucidsonicdreams_class.mp3',\n",
        "                    contrast_audio = 'lucidsonicdreams_pulse.mp3',\n",
        "                    style = 'wikiart')\n",
        "\n",
        "L.hallucinate('lucidsonicdreams.mp4',\n",
        "              resolution = 360,\n",
        "              start = 32, \n",
        "              duration = 60, \n",
        "              pulse_react = 0.25,\n",
        "              motion_react = 0,\n",
        "              classes = [1,5,9,16,23,27,28,30,50,68,71,89],\n",
        "              dominant_classes_first = True,\n",
        "              class_shuffle_seconds = 8,\n",
        "              class_smooth_seconds = 4,\n",
        "              class_pitch_react = 0.2,\n",
        "              contrast_strength = 0.3, \n",
        "              flash_strength = 0.1)\n",
        "\n",
        "files.download(\"lucidsonicdreams.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCtsl9pCeuua"
      },
      "source": [
        "## B.4. Using Custom Effects\n",
        "\n",
        "You can apply your own reactive custom effects to the video by defining an effects function and passing it to an EffectsGenerator object, as seen below. \n",
        "\n",
        "The effects function must contain the following parameters:\n",
        "\n",
        "*   **array** - Refers to the image array that the effect is applied on.\n",
        "*   **strength** - Reactivity parameter, similar to pulse_react, contrast_strength, etc.\n",
        "*   **amplitude** - Refers to the volume of the audio at a given point in time. Simply multiply this to the parameter that controls the \"intensity\" of the effect.\n",
        "\n",
        "The function must output an NumPy array representing the output image\n",
        "\n",
        "The function is then passed to an EffectsGenerator object, which in turn has the following parameters: \n",
        "\n",
        "*   **func** - The effects function\n",
        "*   **audio** - Audio controlling the effect\n",
        "*   **strength** - Strength of the effect\n",
        "*   **percussive** - If True, effect reacts to the audio's percussive elements.\n",
        "\n",
        "The song used in the example below is **Unfaith by Ekali**. You can listen to the full track on [YouTube](https://youtu.be/8C4wgzP1KOI) or [Spotify](https://open.spotify.com/track/5UC6HF9VVgYMHQ7PcwcZNZ?si=hCIA2JMTQTC98zzPZfA3yQ).  \n",
        "\n",
        "Click [here](https://youtu.be/V7jo281HSwM) to view a sample video without having to run the code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I9s10x-cchM"
      },
      "source": [
        "import numpy as np \n",
        "from skimage.transform import swirl\n",
        "from lucidsonicdreams import EffectsGenerator\n",
        "\n",
        "def swirl_func(array, strength, amplitude):\n",
        "  swirled_image = swirl(array, \n",
        "                        rotation = 0, \n",
        "                        strength = 100 * strength * amplitude,\n",
        "                        radius=650)\n",
        "  return (swirled_image*255).astype(np.uint8)\n",
        "\n",
        "swirl_effect = EffectsGenerator(swirl_func,\n",
        "                                audio = 'unfaith.mp3', \n",
        "                                strength = 0.2, \n",
        "                                percussive = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfuiaKo5SIFK"
      },
      "source": [
        "L = LucidSonicDream('unfaith.mp3',\n",
        "                    style = 'textures')\n",
        "\n",
        "L.hallucinate('unfaith.mp4',\n",
        "              resolution = 360,\n",
        "              duration = 60, \n",
        "              motion_react = 0.15,\n",
        "              speed_fpm = 2,\n",
        "              pulse_react = 1.5,\n",
        "              contrast_strength = 1,\n",
        "              flash_strength = 1, \n",
        "              custom_effects = [swirl_effect])\n",
        "\n",
        "files.download(\"unfaith.mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9De3fqCxmTwc"
      },
      "source": [
        "## B.5. Using Custom Visualization Functions\n",
        "\n",
        "Finally, you can choose not to use StyleGAN, and instead define any custom function that takes in a batches of vectors and outputs a Pillow image. The function must take in **noise_batch** and **class_batch** parameters. Moreover, when defining the LucidSonicDream object, **num_possible_classes** and **input_size** must be passed.\n",
        "\n",
        "The example below defines a custom function using a pre-trained PyTorch implementation of the BigGAN, similarly to the [Deep Music Visualizer](https://github.com/msieg/deep-music-visualizer) project by Matt Siegelman. Numerical labels for each class can be found [here](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a). \n",
        "\n",
        "The song used is **Sea of Voices by Porter Robinson**. You can listen to the track on [YouTube](https://www.youtube.com/watch?v=lSooYPG-5Rg) or [Spotify](https://open.spotify.com/track/2lNFWUrxuNaQsf5I1pDTPr?si=MsD7GJUsRma4mkyfjbEhJg). Note that an [instrumental version](https://youtu.be/2Bo0JqTmVwg) was used as input in order to prevent vocals from influencing motion.\n",
        "\n",
        "Click [here](https://youtu.be/_TJCql7O9kU?t=180) to view a full-length sample video without having to run the code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLYJkeRLfTJE"
      },
      "source": [
        "! pip install pytorch_pretrained_biggan\n",
        "from pytorch_pretrained_biggan import BigGAN, convert_to_images\n",
        "import torch\n",
        "\n",
        "biggan = BigGAN.from_pretrained('biggan-deep-512')\n",
        "biggan.to('cuda:0')\n",
        "\n",
        "def biggan_func(noise_batch, class_batch):\n",
        "  noise_tensor = torch.from_numpy(noise_batch).cuda()\n",
        "  class_tensor = torch.from_numpy(class_batch).cuda()\n",
        "  with torch.no_grad():\n",
        "    output_tensor = biggan(noise_tensor.float(), class_tensor.float(), truncation = 1)\n",
        "  return convert_to_images(output_tensor.cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YheSh3p6m7GI"
      },
      "source": [
        "L = LucidSonicDream('sea_of_voices_inst.mp3',\n",
        "                    style = biggan_func, \n",
        "                    input_shape = 128, \n",
        "                    num_possible_classes = 1000)\n",
        "\n",
        "L.hallucinate('sea_of_voices.mp4',\n",
        "              output_audio = 'sea_of_voices.mp3',\n",
        "              resolution = 360,\n",
        "              duration = 60,\n",
        "              speed_fpm = 3,\n",
        "              classes = [13, 14, 22, 24, 301, 84, 99, 100, 134, 143, 393, 394],\n",
        "              class_shuffle_seconds = 10, \n",
        "              class_shuffle_strength = 0.1,\n",
        "              class_complexity = 0.5,\n",
        "              class_smooth_seconds = 4,\n",
        "              motion_react = 0.35,\n",
        "              flash_strength = 1,\n",
        "              contrast_strength = 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}