â€œFast Firstâ€ Roll-out â€“ day-zero cleanup (no KV, no OAuth yet)
Everything below can be completed without adding any new storage layer or auth provider.

1 Â· New shared helpers (Â±200 LOC total)
File	Key exports	Notes
shared/auth-utils.js	extractToken(req) â€¢ extractReferrer(req) â€¢ shouldBypassQueue(req, ctx) â€¢ validateApiTokenDb(token)	ctx = { legacyTokens, allowlist } âœ…
shared/ipQueue.js	enqueue(req, fn, opts)	loads config from shared/.env; wraps p-queue âœ…

1.1 extractToken(req)
js
Copy
Edit
export function extractToken(req) {
  const q = new URL(req.url, 'http://x').searchParams.get('token');
  const hdr = req.headers.get?.('authorization')?.replace(/^Bearer\s+/i,'') ||
              req.headers.get?.('x-pollinations-token');
  return q || hdr || null;            // header/query only â€“ no referrer here!
}
1.2 shouldBypassQueue
js
Copy
Edit
export async function shouldBypassQueue(req, { legacyTokens, allowlist }) {
  const token = extractToken(req);
  const ref   = extractReferrer(req);
  // 1ï¸âƒ£ DB token
  if (token) {
    const userId = await validateApiTokenDb(token);   // Uses auth.pollinations.ai API
    if (userId) return { bypass:true, reason:'DB_TOKEN', userId };
  }
  // 2ï¸âƒ£ legacy token (header/query **or** inside referrer)
  const legacyHit = legacyTokens.includes(token) ||
                    (ref && legacyTokens.some(t => ref.includes(t)));
  if (legacyHit)  return { bypass:true, reason:'LEGACY_TOKEN', userId:null };
  // 3ï¸âƒ£ allow-listed domain
  if (allowlist.some(d => ref?.includes(d)))
       return { bypass:true, reason:'ALLOWLIST', userId:null };
  // 4ï¸âƒ£ default â†’ go through queue
  return { bypass:false, reason:'NONE', userId:null };
}
1.3 enqueue
js
Copy
Edit
import PQueue from 'p-queue';
import { shouldBypassQueue } from './auth-utils.js';
import dotenv from 'dotenv';
import path from 'path';
import { fileURLToPath } from 'url';

// Load environment variables from shared .env file
const __dirname = path.dirname(fileURLToPath(import.meta.url));
dotenv.config({ path: path.join(__dirname, '.env') });

// Load auth context from environment
const legacyTokens = process.env.LEGACY_TOKENS ? process.env.LEGACY_TOKENS.split(',') : [];
const allowlist = process.env.ALLOWLISTED_DOMAINS ? process.env.ALLOWLISTED_DOMAINS.split(',') : [];
const globalAuthCtx = { legacyTokens, allowlist };

// Queue storage
const queues = new Map();

export async function enqueue(req, fn, { interval=6000, cap=1 }={}) {
  const { bypass } = await shouldBypassQueue(req, globalAuthCtx);
  if (bypass) return fn();
  const ip = req.headers.get?.('cf-connecting-ip') || req.headers['cf-connecting-ip'] || req.ip || 'unknown';
  if (!queues.has(ip))
       queues.set(ip, new PQueue({ concurrency:1, interval, intervalCap:cap }));
  return queues.get(ip).add(fn);
}
2 Â· Service-level patches (â‰ˆ30 LOC each)
2.1 text.pollinations.ai/server.js
diff
Copy
Edit
- import PQueue from 'p-queue';           // remove PQueue import
- const queues = new Map();               // remove queue map
- function getQueue(ip) { ... }           // remove queue function
- const queue = getQueue(ip);             // remove queue lookup
- await queue.add(() => processRequest());
+ import { enqueue } from '../shared/ipQueue.js';
+ await enqueue(req, () => processRequest(), {
+     interval: Number(process.env.QUEUE_INTERVAL_MS_TEXT||6000)
+ });
2.2 image.pollinations.ai/src/index.js
diff
Copy
Edit
- const q = ipQueue[ip] || (ipQueue[ip] = new PQueue(...));
- await q.add(() => generateStuff());
+ import { enqueue } from '../../shared/ipQueue.js';
+ await enqueue(req, () => generateStuff(), {
+     interval: Number(process.env.QUEUE_INTERVAL_MS_IMAGE||10000)
+ });
(Delete ipQueue{} definition and its cleanup code.)

3 Â· Environment template (.env.example)
env
Copy
Edit
# legacy tokens (comma-sep)
LEGACY_TOKENS=foo123,bar456

# optional allow-listed referrer domains
ALLOWLISTED_DOMAINS=pollinations.ai,roblox.com

# per-service queue timing (ms per request)
QUEUE_INTERVAL_MS_TEXT=6000
QUEUE_INTERVAL_MS_IMAGE=10000

# feature flag â€“ use shared helpers (set false to roll back instantly)
USE_SHARED_AUTH_AND_QUEUE=true
4 Â· Phased schedule (2Â½ engineering days)
Day	Tasks	Output
0 AM	create /shared; stub helpers; copy env template	repo ready âœ…
0 PM	implement auth-utils, ipQueue; add Jest unit tests covering: DB token ok / legacy header / legacy referrer / deny	CI green âœ…
1 AM	patch text service; remove old queue code; local smoke test	text passes ðŸ”„
1 PM	patch image service; prune ipQueue object; local smoke test	image passes ðŸ”„
1 EOD	deploy to staging with USE_SHARED_AUTH_AND_QUEUE=true; tail logs to compare authReason, latency	validation
2 AM	prod flip of flag; set alert (5xx > baseline+1 %)	live
2 PM	cleanup: delete old queue helpers; document new flow	done

5 Â· Testing checklist
âœ… Unit (Jest): 100 % branches in shouldBypassQueue.

âœ… Integration: curl sequences

-H"Authorization: Bearer <dbToken>" â†’ 200 & reason=DB_TOKEN

?token=<legacy> â†’ 200 & reason=LEGACY_TOKEN

Referer: https://foo.com?bar=<legacy> â†’ 200 & reason=LEGACY_TOKEN

no token, bad referrer â†’ queued â†’ either success after delay or 429 if queue full.

âœ… Compare P99 latency before/after (expect same or lower â€“ less duplicated code).

6 Â· Rollback (instant)
bash
Copy
Edit
export USE_SHARED_AUTH_AND_QUEUE=false   # back to legacy per-service paths
pm2 restart all   # or redeploy worker
No code revert required.

7 Â· Next ready steps (later, not blocking)
Queue scaling â€“ optional KV adapter can slot into ipQueue.js.

DB tiers â€“ add tier column; downstream code branches on userId tier (queue interval, model limits, etc.) without touching shouldBypassQueue.

Result:

Critical referrer-auth bug closed.

One authoritative auth + queue layer across both back-ends.

Ships in ~2 days, no new infra, and leaves clean seams for future upgrades.

## Implementation Notes

1. **Auth API Integration**:
   - Using auth.pollinations.ai API for token validation instead of direct DB access
   - Created validateApiTokenDb function that calls the auth service endpoint
   - Removed DB dependency from the context object

2. **Environment Management**:
   - Shared utilities now load environment variables directly from shared/.env file
   - No need for services to pass auth context - it's handled automatically
   - Simplified integration with services - just import and use

3. **Package Management**:
   - Added package.json to shared folder with required dependencies
   - Using node-fetch for API calls to auth service

4. **Next Steps**:
   - âœ… Complete integration with text.pollinations.ai service
   - âœ… Complete integration with image.pollinations.ai service
   - Add unit tests for the shared utilities