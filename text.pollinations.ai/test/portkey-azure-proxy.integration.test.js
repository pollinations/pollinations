import test from "ava";
import dotenv from "dotenv";
import { generateTextPortkey } from "../generateTextPortkey.js";
import debug from "debug";

const log = debug("pollinations:test:portkey-azure-proxy");
const errorLog = debug("pollinations:test:portkey-azure-proxy:error");

dotenv.config();

// Configure higher timeout for all tests
test.beforeEach((t) => {
    t.timeout(60000); // 60 seconds in milliseconds
});

// Handle unhandled rejections
process.on("unhandledRejection", (reason, promise) => {
    errorLog("Unhandled Rejection at:", promise, "reason:", reason);
    // Don't exit the process, just log the error
});

/**
 * Test: Basic Text Generation with gpt-4o-mini
 *
 * Purpose: Verify that the Portkey Azure proxy can generate text with gpt-4o-mini
 *
 * Expected behavior:
 * 1. The response should match OpenAI format
 * 2. The response should contain meaningful text
 */
test.serial(
    "should generate text with openai model (gpt-4o-mini)",
    async (t) => {
        const messages = [{ role: "user", content: "Hello, how are you?" }];
        const options = { model: "openai", temperature: 0.7 };

        try {
            const response = await generateTextPortkey(messages, options);

            // If API is available and returns a valid response
            if (
                response.choices &&
                response.choices[0] &&
                response.choices[0].message
            ) {
                t.is(
                    typeof response.choices[0].message.content,
                    "string",
                    "Response should be a string",
                );
                t.true(
                    response.choices[0].message.content.length > 0,
                    "Response should not be empty",
                );
                t.is(
                    response.choices[0].message.role,
                    "assistant",
                    "Response role should be assistant",
                );

                // Log the response for debugging
                log(
                    "Response from openai (gpt-4o-mini):",
                    response.choices[0].message.content,
                );
                log("Response metadata:", {
                    model: response.model,
                    usage: response.usage,
                });
            } else if (response.error) {
                // If API returns an error, skip the test
                t.pass(
                    "Skipping test due to API error: " + response.error.message,
                );
            }
        } catch (error) {
            // If there's an exception, skip the test
            t.pass("Skipping test due to exception: " + error.message);
        }
    },
);

/**
 * Test: Text Generation with openai-large (gpt-4o)
 *
 * Purpose: Verify that the Portkey Azure proxy can generate text with gpt-4o
 *
 * Expected behavior:
 * 1. The response should match OpenAI format
 * 2. The response should contain meaningful text
 */
test.serial(
    "should generate text with openai-large model (gpt-4o)",
    async (t) => {
        const messages = [
            {
                role: "user",
                content: "Explain quantum computing in simple terms.",
            },
        ];
        const options = { model: "openai-large", temperature: 0.7 };

        try {
            const response = await generateTextPortkey(messages, options);

            // If API is available and returns a valid response
            if (
                response.choices &&
                response.choices[0] &&
                response.choices[0].message
            ) {
                t.is(
                    typeof response.choices[0].message.content,
                    "string",
                    "Response should be a string",
                );
                t.true(
                    response.choices[0].message.content.length > 0,
                    "Response should not be empty",
                );
                t.is(
                    response.choices[0].message.role,
                    "assistant",
                    "Response role should be assistant",
                );

                // Log the response for debugging
                log(
                    "Response from openai-large (gpt-4o):",
                    response.choices[0].message.content,
                );
                log("Response metadata:", {
                    model: response.model,
                    usage: response.usage,
                });
            } else if (response.error) {
                // If API returns an error, skip the test
                t.pass(
                    "Skipping test due to API error: " + response.error.message,
                );
            }
        } catch (error) {
            // If there's an exception, skip the test
            t.pass("Skipping test due to exception: " + error.message);
        }
    },
);

/**
 * Test: Text Generation with openai-reasoning (o1-mini)
 *
 * Purpose: Verify that the Portkey Azure proxy can generate text with o1-mini
 *
 * Expected behavior:
 * 1. The response should match OpenAI format
 * 2. The response should contain meaningful text
 */
test.serial(
    "should generate text with openai-reasoning model (o1-mini)",
    async (t) => {
        const messages = [{ role: "user", content: "What is 15 + 27?" }];
        const options = { model: "openai-reasoning", temperature: 0.7 };

        try {
            const response = await generateTextPortkey(messages, options);

            // If API is available and returns a valid response
            if (
                response.choices &&
                response.choices[0] &&
                response.choices[0].message
            ) {
                t.is(
                    typeof response.choices[0].message.content,
                    "string",
                    "Response should be a string",
                );
                t.true(
                    response.choices[0].message.content.length > 0,
                    "Response should not be empty",
                );
                t.is(
                    response.choices[0].message.role,
                    "assistant",
                    "Response role should be assistant",
                );

                // Log the response for debugging
                log(
                    "Response from openai-reasoning (o1-mini):",
                    response.choices[0].message.content,
                );
                log("Response metadata:", {
                    model: response.model,
                    usage: response.usage,
                });
            } else if (response.error) {
                // If API returns an error, skip the test
                t.pass(
                    "Skipping test due to API error: " + response.error.message,
                );
            }
        } catch (error) {
            // If there's an exception, skip the test
            t.pass("Skipping test due to exception: " + error.message);
        }
    },
);

/**
 * Test: JSON Mode
 *
 * Purpose: Verify that JSON mode returns properly formatted JSON
 *
 * Expected behavior:
 * 1. The response should be valid JSON
 */
test.serial("should handle JSON mode correctly", async (t) => {
    const messages = [
        {
            role: "user",
            content:
                "Generate a JSON object with name, age, and hobbies fields.",
        },
    ];
    const options = { model: "openai", jsonMode: true };

    try {
        const response = await generateTextPortkey(messages, options);

        // If API is available and returns a valid response
        if (
            response.choices &&
            response.choices[0] &&
            response.choices[0].message
        ) {
            const content = response.choices[0].message.content;
            t.is(typeof content, "string", "Response should be a string");

            // Try to parse as JSON
            try {
                const parsed = JSON.parse(content);
                t.true(
                    typeof parsed === "object",
                    "Parsed content should be an object",
                );
                t.true(parsed !== null, "Parsed content should not be null");

                // Log the parsed JSON for debugging
                log("Parsed JSON response:", parsed);
            } catch (e) {
                // If JSON parsing fails but we're in JSON mode, that's a test failure
                // unless the API returned an error
                if (response.error) {
                    t.pass("Skipping JSON parsing test due to API error");
                } else {
                    t.fail(
                        `Response in JSON mode is not valid JSON: ${e.message}`,
                    );
                }
            }
        } else if (response.error) {
            // If API returns an error, skip the test
            t.pass("Skipping test due to API error: " + response.error.message);
        }
    } catch (error) {
        // If there's an exception, skip the test
        t.pass("Skipping test due to exception: " + error.message);
    }
});
