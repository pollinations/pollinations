import test from "ava";
import dotenv from "dotenv";
import { generateTextPortkey } from "../generateTextPortkey.js";
import debug from "debug";

const log = debug("pollinations:test:portkey-azure");
const errorLog = debug("pollinations:test:portkey-azure:error");

dotenv.config();

// Configure higher timeout for all tests
test.beforeEach((t) => {
    t.timeout(60000); // 60 seconds in milliseconds
});

// Handle unhandled rejections
process.on("unhandledRejection", (reason, promise) => {
    errorLog("Unhandled Rejection at:", promise, "reason:", reason);
    // Don't exit the process, just log the error
});

/**
 * Test: Basic Text Generation with gpt-4o-mini
 *
 * Purpose: Verify that the Portkey Azure integration can generate text with gpt-4o-mini
 *
 * Expected behavior:
 * 1. The response should match OpenAI format
 * 2. The response should contain meaningful text
 */
test.serial("should generate text with gpt-4o-mini model", async (t) => {
    const messages = [{ role: "user", content: "Hello, how are you?" }];
    const options = { model: "openai", temperature: 0.7 };

    try {
        const response = await generateTextPortkey(messages, options);

        // If API is available and returns a valid response
        if (
            response.choices &&
            response.choices[0] &&
            response.choices[0].message
        ) {
            t.is(
                typeof response.choices[0].message.content,
                "string",
                "Response should be a string",
            );
            t.true(
                response.choices[0].message.content.length > 0,
                "Response should not be empty",
            );
            t.is(
                response.choices[0].message.role,
                "assistant",
                "Response role should be assistant",
            );

            // Log the response for debugging
            log(
                "Response from gpt-4o-mini:",
                response.choices[0].message.content,
            );
            log("Response metadata:", {
                model: response.model,
                usage: response.usage,
            });
        } else if (response.error) {
            // If API returns an error, skip the test
            t.pass("Skipping test due to API error: " + response.error.message);
        }
    } catch (error) {
        // If there's an exception, skip the test
        t.pass("Skipping test due to exception: " + error.message);
    }
});

/**
 * Test: Text Generation with gpt-4o (large model)
 *
 * Purpose: Verify that the Portkey Azure integration can generate text with gpt-4o
 *
 * Expected behavior:
 * 1. The response should match OpenAI format
 * 2. The response should contain meaningful text
 */
test.serial("should generate text with gpt-4o (large) model", async (t) => {
    const messages = [
        { role: "user", content: "Explain quantum computing in simple terms." },
    ];
    const options = { model: "openai-large", temperature: 0.7 };

    try {
        const response = await generateTextPortkey(messages, options);

        // If API is available and returns a valid response
        if (
            response.choices &&
            response.choices[0] &&
            response.choices[0].message
        ) {
            t.is(
                typeof response.choices[0].message.content,
                "string",
                "Response should be a string",
            );
            t.true(
                response.choices[0].message.content.length > 0,
                "Response should not be empty",
            );
            t.is(
                response.choices[0].message.role,
                "assistant",
                "Response role should be assistant",
            );

            // Log the response for debugging
            log("Response from gpt-4o:", response.choices[0].message.content);
            log("Response metadata:", {
                model: response.model,
                usage: response.usage,
            });
        } else if (response.error) {
            // If API returns an error, skip the test
            t.pass("Skipping test due to API error: " + response.error.message);
        }
    } catch (error) {
        // If there's an exception, skip the test
        t.pass("Skipping test due to exception: " + error.message);
    }
});

/**
 * Test: Text Generation with o1-mini (reasoning model)
 *
 * Purpose: Verify that the Portkey Azure integration can generate text with o1-mini
 *
 * Expected behavior:
 * 1. The response should match OpenAI format
 * 2. The response should contain meaningful text
 */
test.serial(
    "should generate text with o1-mini (reasoning) model",
    async (t) => {
        const messages = [{ role: "user", content: "What is 15 + 27?" }];
        const options = { model: "openai-reasoning", temperature: 0.7 };

        try {
            const response = await generateTextPortkey(messages, options);

            // If API is available and returns a valid response
            if (
                response.choices &&
                response.choices[0] &&
                response.choices[0].message
            ) {
                t.is(
                    typeof response.choices[0].message.content,
                    "string",
                    "Response should be a string",
                );
                t.true(
                    response.choices[0].message.content.length > 0,
                    "Response should not be empty",
                );
                t.is(
                    response.choices[0].message.role,
                    "assistant",
                    "Response role should be assistant",
                );

                // Log the response for debugging
                log(
                    "Response from o1-mini:",
                    response.choices[0].message.content,
                );
                log("Response metadata:", {
                    model: response.model,
                    usage: response.usage,
                });
            } else if (response.error) {
                // If API returns an error, skip the test
                t.pass(
                    "Skipping test due to API error: " + response.error.message,
                );
            }
        } catch (error) {
            // If there's an exception, skip the test
            t.pass("Skipping test due to exception: " + error.message);
        }
    },
);

/**
 * Test: System Message Handling
 *
 * Purpose: Verify that system messages are handled correctly
 *
 * Expected behavior:
 * 1. The response should reflect the behavior defined in the system message
 */
test.serial("should handle system messages correctly", async (t) => {
    const messages = [
        {
            role: "system",
            content:
                "You are a helpful assistant who always responds with exactly three sentences.",
        },
        { role: "user", content: "Tell me about the moon." },
    ];
    const options = { model: "openai" };

    try {
        const response = await generateTextPortkey(messages, options);

        // If API is available and returns a valid response
        if (
            response.choices &&
            response.choices[0] &&
            response.choices[0].message
        ) {
            const content = response.choices[0].message.content;
            t.is(typeof content, "string", "Response should be a string");
            t.true(content.length > 0, "Response should not be empty");

            // Count sentences (simple approximation)
            const sentenceCount =
                (content.match(/[.!?]+\s/g) || []).length +
                (content.endsWith(".") ||
                content.endsWith("!") ||
                content.endsWith("?")
                    ? 1
                    : 0);

            // Allow some flexibility in sentence count (3 +/- 1)
            t.true(
                sentenceCount >= 2 && sentenceCount <= 4,
                `Response should have approximately 3 sentences, got ${sentenceCount}`,
            );

            // Log the response for debugging
            log("Response with system message:", content);
            log("Sentence count:", sentenceCount);
        } else if (response.error) {
            // If API returns an error, skip the test
            t.pass("Skipping test due to API error: " + response.error.message);
        }
    } catch (error) {
        // If there's an exception, skip the test
        t.pass("Skipping test due to exception: " + error.message);
    }
});

/**
 * Test: JSON Mode
 *
 * Purpose: Verify that JSON mode returns properly formatted JSON
 *
 * Expected behavior:
 * 1. The response should be valid JSON
 */
test.serial("should handle JSON mode correctly", async (t) => {
    const messages = [
        {
            role: "user",
            content:
                "Generate a JSON object with name, age, and hobbies fields.",
        },
    ];
    const options = { model: "openai", jsonMode: true };

    try {
        const response = await generateTextPortkey(messages, options);

        // If API is available and returns a valid response
        if (
            response.choices &&
            response.choices[0] &&
            response.choices[0].message
        ) {
            const content = response.choices[0].message.content;
            t.is(typeof content, "string", "Response should be a string");

            // Try to parse as JSON
            try {
                const parsed = JSON.parse(content);
                t.true(
                    typeof parsed === "object",
                    "Parsed content should be an object",
                );
                t.true(parsed !== null, "Parsed content should not be null");

                // Log the parsed JSON for debugging
                log("Parsed JSON response:", parsed);
            } catch (e) {
                // If JSON parsing fails but we're in JSON mode, that's a test failure
                // unless the API returned an error
                if (response.error) {
                    t.pass("Skipping JSON parsing test due to API error");
                } else {
                    t.fail(
                        `Response in JSON mode is not valid JSON: ${e.message}`,
                    );
                }
            }
        } else if (response.error) {
            // If API returns an error, skip the test
            t.pass("Skipping test due to API error: " + response.error.message);
        }
    } catch (error) {
        // If there's an exception, skip the test
        t.pass("Skipping test due to exception: " + error.message);
    }
});

/**
 * Test: Tool Usage
 *
 * Purpose: Verify that the model can use tools when provided
 *
 * Expected behavior:
 * 1. The response should include tool calls when tools are provided
 */
test.serial("should handle tools correctly", async (t) => {
    const messages = [
        { role: "user", content: "What's the weather like in New York?" },
    ];

    const tools = [
        {
            type: "function",
            function: {
                name: "get_weather",
                description: "Get the current weather in a given location",
                parameters: {
                    type: "object",
                    properties: {
                        location: {
                            type: "string",
                            description:
                                "The city and state, e.g. San Francisco, CA",
                        },
                        unit: {
                            type: "string",
                            enum: ["celsius", "fahrenheit"],
                            description: "The temperature unit to use",
                        },
                    },
                    required: ["location"],
                },
            },
        },
    ];

    const options = {
        model: "openai",
        tools: tools,
        tool_choice: "auto",
    };

    try {
        const response = await generateTextPortkey(messages, options);

        // If API is available and returns a valid response
        if (response.choices && response.choices[0]) {
            // Check if tool calls are present or if there's a regular message
            if (response.choices[0].message.tool_calls) {
                const toolCalls = response.choices[0].message.tool_calls;
                t.true(
                    Array.isArray(toolCalls),
                    "Tool calls should be an array",
                );
                t.true(
                    toolCalls.length > 0,
                    "Should have at least one tool call",
                );

                // Check the first tool call
                const firstCall = toolCalls[0];
                t.is(
                    firstCall.function.name,
                    "get_weather",
                    "Should call the weather function",
                );

                // Try to parse the arguments
                try {
                    const args = JSON.parse(firstCall.function.arguments);
                    t.true(
                        typeof args.location === "string",
                        "Location should be a string",
                    );
                    t.true(
                        args.location.toLowerCase().includes("new york"),
                        "Location should include New York",
                    );

                    // Log the function call for debugging
                    log("Function call:", firstCall);
                    log("Function arguments:", args);
                } catch (e) {
                    t.fail(
                        `Tool call arguments are not valid JSON: ${e.message}`,
                    );
                }
            } else if (response.choices[0].message.content) {
                // If no tool calls but there's content, that's acceptable too
                // (the model might choose not to use tools)
                t.pass(
                    "Model chose not to use tools, but provided a text response",
                );
                log("Text response:", response.choices[0].message.content);
            } else if (response.error) {
                // If API returns an error, skip the test
                t.pass(
                    "Skipping test due to API error: " + response.error.message,
                );
            }
        } else if (response.error) {
            // If API returns an error, skip the test
            t.pass("Skipping test due to API error: " + response.error.message);
        }
    } catch (error) {
        // If there's an exception, skip the test
        t.pass("Skipping test due to exception: " + error.message);
    }
});
